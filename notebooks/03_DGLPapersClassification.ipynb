{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from IPython.display import Image\n",
    "import pygraphviz as pgv\n",
    "import scipy.io\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation graph\n",
    "\n",
    "References:\n",
    "https://arxiv.org/pdf/1511.04854.pdf\n",
    "\n",
    "Given: below citation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<img src=\"https://data.dgl.ai/tutorial/hetero/acm-example.png\"/>",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "Image(url='https://data.dgl.ai/tutorial/hetero/acm-example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try visualize above citation graph as DGL heterenous graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Graph(num_nodes={'author': 4, 'paper': 3, 'venue': 2},\n      num_edges={('author', 'writing', 'paper'): 8, ('paper', 'citing', 'paper'): 1, ('venue', 'publishing', 'paper'): 3},\n      metagraph=[('author', 'paper'), ('paper', 'paper'), ('venue', 'paper')])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "writing_edges = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 1), (3, 2)]\n",
    "citing_edges = [(2, 0)]\n",
    "publishing_edges = [(0,0), (1,1), (1,2)]\n",
    "\n",
    "writting_g = dgl.bipartite(writing_edges, 'author', 'writing', 'paper')\n",
    "citting_g = dgl.graph(citing_edges, 'paper', 'citing')\n",
    "publishing_g = dgl.bipartite(publishing_edges, 'venue', 'publishing', 'paper')\n",
    "citatation_graph = dgl.hetero_from_relations([writting_g, citting_g, publishing_g])\n",
    "\n",
    "citatation_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heterograph(nxg, filepath):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "    \n",
    "    ag.layout('dot')\n",
    "    ag.draw(filepath)\n",
    "\n",
    "plot_heterograph(citatation_graph.metagraph, 'img/citation_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<img src=\"img/citation_graph.png\"/>",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "Image(url='img/citation_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag1 = pgv.AGraph(strict=False, directed=True)\n",
    "for we in writing_edges:\n",
    "    ag1.add_edge('a'+str(we[0]), 'p'+str(we[1]), label='writing')\n",
    "\n",
    "for ce in citing_edges:\n",
    "    ag1.add_edge('p'+str(ce[0]), 'p'+str(ce[1]), label='citing')\n",
    "\n",
    "for pe in publishing_edges:\n",
    "    ag1.add_edge('v'+str(pe[0]), 'p'+str(pe[1]), label='publishing')\n",
    "\n",
    "ag1.layout('dot')\n",
    "ag1.draw('img/citation_heteroneusgraph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<img src=\"img/citation_heteroneusgraph.png\"/>",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "Image(url='img/citation_heteroneusgraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create more realistic heterograph, we use the ACM dataset, which contains information about papers citation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n"
    }
   ],
   "source": [
    "data_url = 'https://data.dgl.ai/dataset/ACM.mat'\n",
    "data_file_path = './data/ACM.mat'\n",
    "\n",
    "urllib.request.urlretrieve(data_url, data_file_path)\n",
    "data = scipy.io.loadmat(data_file_path)\n",
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num of papers:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12499"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "print('Num of papers:')\n",
    "data['PvsA'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num of authors:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "17431"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print('Num of authors:')\n",
    "data['PvsA'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Links beetwen authors and papers:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "37055"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "print('Links beetwen authors and papers:')\n",
    "data['PvsA'].nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we analyze paper-author relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Graph(num_nodes={'paper': 12499, 'author': 17431},\n      num_edges={('paper', 'written-by', 'author'): 37055},\n      metagraph=[('paper', 'author')])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "paper_vs_author_g = dgl.bipartite(data['PvsA'], 'paper', 'written-by', 'author')\n",
    "paper_vs_author_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = dgl.heterograph({\n",
    "        ('paper', 'written-by', 'author') : data['PvsA'],\n",
    "        ('author', 'writing', 'paper') : data['PvsA'].transpose(),\n",
    "        ('paper', 'citing', 'paper') : data['PvsP'],\n",
    "        ('paper', 'cited', 'paper') : data['PvsP'].transpose(),\n",
    "        ('paper', 'is-about', 'subject') : data['PvsL'],\n",
    "        ('subject', 'has', 'paper') : data['PvsL'].transpose(),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heterograph(G.metagraph, 'img/acm_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<img src=\"img/acm_graph.png\"/>",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "Image(url='img/acm_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node classification and regression to predict the class of each node or estimate a value associated with it\n",
    "\n",
    "Goal: predict the publishing conference of a paper.\n",
    "\n",
    "Description:\n",
    "Dataset contains 14 different conferences, to make our classification semi-supervised, let's labeled only the last four of them. \n",
    "\n",
    "Refrences:\n",
    "https://docs.dgl.ai/tutorials/basics/5_hetero.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvc = data['PvsC'].tocsr()\n",
    "selected_conferences = [10, 11, 12, 13]\n",
    "selected_papers = pvc[:, selected_conferences].tocoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label last four nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pvc.indices\n",
    "labels[labels == 10] = 0\n",
    "labels[labels == 11] = 1\n",
    "labels[labels == 12] = 2\n",
    "labels[labels == 13] = 3\n",
    "labels = torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset to train, val and test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = selected_papers.row\n",
    "shuffle = np.random.permutation(pid)\n",
    "train = torch.tensor(shuffle[0:800]).long()\n",
    "val = torch.tensor(shuffle[800:900]).long()\n",
    "test = torch.tensor(shuffle[900:]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning the represantation of nodes in the graph using Relational-GCN needs two steps:\n",
    "\n",
    "1. Message computation and aggregation within each relation\n",
    "2. Reduction that merges the results from multiple relationships.\n",
    "\n",
    "In heteroRGCNLayer, we keep weights for each relation. We have to also define forward function, where\n",
    "\n",
    "- Compute W_r (relation weight) * h,\n",
    "- Save that value,\n",
    "- Specify per-relation message passing functions,\n",
    "- Trigger message passing of multiple types,\n",
    "- Return the updated node feature dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "\n",
    "        G.multi_update_all(funcs, 'mean')\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will create simple GNN by stacking two Layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size))\n",
    "                      for ntype in G.ntypes}\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "\n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "\n",
    "        return h_dict['paper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train GCN and evaluate received results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss 1.3580, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 1.3194, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 1.2778, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 1.2256, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 1.1562, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 1.0697, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 0.9777, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 0.8930, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 0.8093, Train Acc 0.5400, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5435 (Best 0.5435)\nLoss 0.7269, Train Acc 0.5725, Val Acc 0.5200 (Best 0.5200), Test Acc 0.5493 (Best 0.5435)\nLoss 0.6438, Train Acc 0.6812, Val Acc 0.6500 (Best 0.6500), Test Acc 0.6519 (Best 0.6519)\nLoss 0.5610, Train Acc 0.7675, Val Acc 0.7100 (Best 0.7100), Test Acc 0.6966 (Best 0.6966)\nLoss 0.4834, Train Acc 0.8675, Val Acc 0.7700 (Best 0.7700), Test Acc 0.7423 (Best 0.7423)\nLoss 0.4110, Train Acc 0.8838, Val Acc 0.8000 (Best 0.8000), Test Acc 0.7803 (Best 0.7803)\nLoss 0.3471, Train Acc 0.9075, Val Acc 0.8400 (Best 0.8400), Test Acc 0.8216 (Best 0.8216)\nLoss 0.2924, Train Acc 0.9300, Val Acc 0.8600 (Best 0.8600), Test Acc 0.8532 (Best 0.8532)\nLoss 0.2478, Train Acc 0.9475, Val Acc 0.8500 (Best 0.8600), Test Acc 0.8717 (Best 0.8532)\nLoss 0.2140, Train Acc 0.9550, Val Acc 0.8500 (Best 0.8600), Test Acc 0.8780 (Best 0.8532)\nLoss 0.1913, Train Acc 0.9550, Val Acc 0.8600 (Best 0.8600), Test Acc 0.8809 (Best 0.8532)\nLoss 0.1742, Train Acc 0.9563, Val Acc 0.8600 (Best 0.8600), Test Acc 0.8814 (Best 0.8532)\n"
    }
   ],
   "source": [
    "model = HeteroRGCN(G, 10, 10, 4)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    logits = model(G)\n",
    "    loss = F.cross_entropy(logits[train], labels[train])\n",
    "\n",
    "    pred = logits.argmax(1)\n",
    "    train_acc = (pred[train] == labels[train]).float().mean()\n",
    "    val_acc = (pred[val] == labels[val]).float().mean()\n",
    "    test_acc = (pred[test] == labels[test]).float().mean()\n",
    "\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print('Loss %.4f, Train Acc %.4f, Val Acc %.4f (Best %.4f), Test Acc %.4f (Best %.4f)' % (\n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We received test evaluation result around 88.14% accuracy, which is quite good on small dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitdglenvconda6fb52be239fa4d548e32a9efd4cf337f",
   "display_name": "Python 3.6.10 64-bit ('dglenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}